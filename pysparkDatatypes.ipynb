{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO+aEMk236b74o/8dBszldY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8aruQ300mQk"
      },
      "outputs": [],
      "source": [
        "! pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from decimal import Decimal\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# ArrayType\n",
        "array_schema = ArrayType(IntegerType())\n",
        "array_data = [[1, 2, 3], [4, 5, 6]]\n",
        "array_df = spark.createDataFrame(array_data, array_schema)\n",
        "array_df.show()\n",
        "\n",
        "# BinaryType\n",
        "binary_schema = BinaryType()\n",
        "binary_data = [bytearray(b'Hello'), bytearray(b'World')]\n",
        "binary_df = spark.createDataFrame(binary_data, binary_schema)\n",
        "binary_df.show()\n",
        "\n",
        "# BooleanType\n",
        "boolean_schema = BooleanType()\n",
        "boolean_data = [True, False, True]\n",
        "boolean_df = spark.createDataFrame(boolean_data, boolean_schema)\n",
        "boolean_df.show()\n",
        "\n",
        "# ByteType\n",
        "byte_schema = ByteType()\n",
        "byte_data = [1, 2, 3]\n",
        "byte_df = spark.createDataFrame(byte_data, byte_schema)\n",
        "byte_df.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DoubleType\n",
        "double_schema = DoubleType()\n",
        "double_data = [1.0, 2.5, 3.7]\n",
        "double_df = spark.createDataFrame(double_data, double_schema)\n",
        "double_df.show()\n",
        "\n",
        "# FloatType\n",
        "float_schema = FloatType()\n",
        "float_data = [1.0, 2.5, 3.7]\n",
        "float_df = spark.createDataFrame(float_data, float_schema)\n",
        "float_df.show()\n",
        "\n",
        "# IntegerType\n",
        "integer_schema = IntegerType()\n",
        "integer_data = [1, 2, 3]\n",
        "integer_df = spark.createDataFrame(integer_data, integer_schema)\n",
        "integer_df.show()\n",
        "\n",
        "# LongType\n",
        "long_schema = LongType()\n",
        "long_data = [1, 2, 3]\n",
        "long_df = spark.createDataFrame(long_data, long_schema)\n",
        "long_df.show()\n",
        "\n",
        "# MapType\n",
        "map_schema = MapType(StringType(), IntegerType())\n",
        "map_data = [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}]\n",
        "map_df = spark.createDataFrame(map_data, map_schema)\n",
        "map_df.show()\n",
        "\n",
        "# NullType\n",
        "null_schema = NullType()\n",
        "null_data = [None, None, None]\n",
        "null_df = spark.createDataFrame(null_data, null_schema)\n",
        "null_df.show()\n",
        "\n",
        "# ShortType\n",
        "short_schema = ShortType()\n",
        "short_data = [1, 2, 3]\n",
        "short_df = spark.createDataFrame(short_data, short_schema)\n",
        "short_df.show()\n",
        "\n",
        "# StringType\n",
        "string_schema = StringType()\n",
        "string_data = ['Hello', 'World', 'PySpark']\n",
        "string_df = spark.createDataFrame(string_data, string_schema)\n",
        "string_df.show()\n",
        "\n",
        "\n",
        "# StructField\n",
        "struct_field_schema = StructType([StructField('name', StringType()), StructField('age', IntegerType())])\n",
        "struct_field_data = [('Alice', 25), ('Bob', 30), ('Charlie', 35)]\n",
        "struct_field_df = spark.createDataFrame(struct_field_data, struct_field_schema)\n",
        "struct_field_df.show()\n",
        "\n",
        "# StructType\n",
        "struct_type_schema = StructType([StructField('name', StringType()), StructField('age', IntegerType())])\n",
        "struct_type_data = [('Alice', 25), ('Bob', 30), ('Charlie', 35)]\n",
        "struct_type_df = spark.createDataFrame(struct_type_data, struct_type_schema)\n",
        "struct_type_df.show()\n",
        "\n",
        "# DateType\n",
        "date_schema = StringType()\n",
        "date_data = ['2022-01-01', '2022-02-01', '2022-03-01']\n",
        "date_df = spark.createDataFrame(date_data, date_schema)\n",
        "date_df = date_df.withColumn(\"date\", to_date(col(\"value\"), \"yyyy-MM-dd\"))\n",
        "date_df.show()\n",
        "\n",
        "# TimestampType\n",
        "timestamp_schema = StringType()\n",
        "timestamp_data = ['2022-01-01 10:00:00', '2022-02-01 12:00:00', '2022-03-01 14:00:00']\n",
        "timestamp_df = spark.createDataFrame(timestamp_data, timestamp_schema)\n",
        "timestamp_df = timestamp_df.withColumn(\"timestamp\", to_timestamp(col(\"value\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "timestamp_df.show()\n",
        "\n",
        "\n",
        "# DecimalType\n",
        "decimal_schema = DecimalType(10, 2)\n",
        "decimal_data = [Decimal('10.50'), Decimal('20.75'), Decimal('30.00')]\n",
        "decimal_df = spark.createDataFrame(decimal_data, decimal_schema)\n",
        "decimal_df.show()\n",
        "\n"
      ]
    }
  ]
}