{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPb2j3NIyUEJU/YjkTyb78q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B5H8UVmeRL3"
      },
      "outputs": [],
      "source": [
        "# Create a sample list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "wlbWPY_Po2B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list = [ 'the','and','have','that','for','you','with','say','this'\n",
        ",'they','but','his','from','not']\n",
        "\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "value = random.randint(1,10)\n",
        "csv_list = []\n",
        "\n",
        "for i in range(value):\n",
        "  csv_list.append(sample_list[i])\n",
        "\n",
        "file_name = \"words\" + str(time.ctime()) + \".csv\"\n",
        "df = pd.DataFrame(csv_list)\n",
        "df.to_csv(file_name,index=False)"
      ],
      "metadata": {
        "id": "tTDTtQ7tnSZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Streaming\n",
        "# Data received from a server listening on TCP socket."
      ],
      "metadata": {
        "id": "0TxEFm65eerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "UXw8HLXvny26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary modules\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql.functions import split\n",
        "from pyspark.sql.types import StructType\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"WordCount\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "RvwUiRnZeqR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataframe - Stream of input toward a host\n",
        "\n",
        "userSchema = StructType().add(\"value\", \"string\")\n",
        "\n",
        "lines = spark \\\n",
        "        .readStream \\\n",
        "        .format(\"csv\") \\\n",
        "        .schema(userSchema) \\\n",
        "        .load(r'/content/wordsTue Feb  6 23:07:34 2024.csv')\n"
      ],
      "metadata": {
        "id": "WtF02KoafHH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines.describe()"
      ],
      "metadata": {
        "id": "0lOqs5t7vF__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the lines into words\n",
        "words = lines.select(explode(split(lines.value,\"\")).alias(\"word\"))"
      ],
      "metadata": {
        "id": "jrPw_IhDgCwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordCounts = words.groupBy(\"word\").count()"
      ],
      "metadata": {
        "id": "_PWWF0YpgZ4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outfilename = str(time.ctime) + \"out.csv\"\n",
        "query = wordCounts.writeStream.format(\"csv\").option(\"checkpointLocation\", \"checkpoint/\").start(\"output/\").awaitTermination()"
      ],
      "metadata": {
        "id": "HtBPSe86xkiC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}