{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMkMxxIN0061RGXY3VVtQAj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B5H8UVmeRL3"
      },
      "outputs": [],
      "source": [
        "# Create a sample list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "wlbWPY_Po2B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list = [ 'the','and','have','that','for','you','with','say','this'\n",
        ",'they','but','his','from','not']\n",
        "\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "value = random.randint(5,10)\n",
        "csv_list = []\n",
        "\n",
        "for i in range(value):\n",
        "  csv_list.append(sample_list[i])\n",
        "\n",
        "file_name = \"words\" + str(time.ctime()) + \".csv\"\n",
        "df = pd.DataFrame(csv_list)\n",
        "df.to_csv(file_name,index=False)"
      ],
      "metadata": {
        "id": "tTDTtQ7tnSZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Streaming\n",
        "# Data received from a server listening on TCP socket."
      ],
      "metadata": {
        "id": "0TxEFm65eerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "UXw8HLXvny26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary modules\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql.functions import split\n",
        "from pyspark.sql.types import StructType\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"WordCount\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "RvwUiRnZeqR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataframe - Stream of input toward a host\n",
        "\n",
        "userSchema = StructType().add(\"value\", \"string\")\n",
        "\n",
        "lines = spark \\\n",
        "        .readStream \\\n",
        "        .format(\"csv\") \\\n",
        "        .schema(userSchema) \\\n",
        "        .load(r'/content/wordsWed Feb  7 04:40:21 2024.csv')\n"
      ],
      "metadata": {
        "id": "WtF02KoafHH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the lines into words\n",
        "words = lines.select(explode(split(lines.value,\"\\n\")).alias(\"word\"))"
      ],
      "metadata": {
        "id": "jrPw_IhDgCwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordCounts = words.groupBy(\"word\").count()\n",
        "words.writeStream \\\n",
        ".format(\"csv\") \\\n",
        ".option(\"checkpointLocation\", \"path/to/checkpoint/dir\") \\\n",
        ".option(\"path\", \"path/to/destination/dir\") \\\n",
        ".start()"
      ],
      "metadata": {
        "id": "_PWWF0YpgZ4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outfilename = str(time.ctime) + \"out.csv\"\n",
        "\n",
        "wordCounts.writeStream \\\n",
        "    .queryName(\"aggregates\") \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .start()"
      ],
      "metadata": {
        "id": "HtBPSe86xkiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from aggregates\").show()"
      ],
      "metadata": {
        "id": "11d2m0nX0U5Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}