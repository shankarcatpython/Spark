{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMX3h6GiipDjoQZeJ9Wq9QJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0und9yKDT9PU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "word_list = [ 'Cabo Verde','Cambodia','Cameroon','Canada','Cayman Islands','Central African Republic'\n",
        ",'Central American Federation','Chad','Chile','China','Colombia','Comoros','Congo Free State','Costa Rica'\n",
        ",'Cote dIvoire Ivory Coast','Croatia','Cuba','Cyprus','Czechia' 'Czechoslovakia']\n",
        "arraylist=[]\n",
        "final_wordlist = []\n",
        "\n",
        "for i in range(1,1000000):\n",
        "    arraylist.append(i)\n",
        "    final_wordlist.append(random.choice(word_list))\n",
        "\n",
        "sizeofnumbers = round((sys.getsizeof(arraylist)/(1024*1024)))\n",
        "sizeofword = round((sys.getsizeof(final_wordlist)/(1024*1024)))\n",
        "\n",
        "output_data = pd.DataFrame({'Number':arraylist,'Country':final_wordlist})\n",
        "\n",
        "print(sizeofnumbers,sizeofword)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "FqGHK0StUPY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data.to_csv('test.csv',index=False)"
      ],
      "metadata": {
        "id": "ffPz4yGzWXXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName('TestAppp') \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "U-qnxV99XHOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe = spark.read.csv(r'/content/test.csv',header=True)"
      ],
      "metadata": {
        "id": "eD-EnssHXo_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.show()"
      ],
      "metadata": {
        "id": "ruDN-fIjXzrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.printSchema()"
      ],
      "metadata": {
        "id": "YFGCZ_SjYtd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.select(\"Number\").show()"
      ],
      "metadata": {
        "id": "64EnzX4iX31g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.select(spark_dataframe['Number']+1).show()"
      ],
      "metadata": {
        "id": "-_A9vWQWY4wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.filter(spark_dataframe['Number']==1).show()"
      ],
      "metadata": {
        "id": "Ofqxn4DEap5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.groupby('Country').count().show()"
      ],
      "metadata": {
        "id": "DA-Lq-4cbPHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.createOrReplaceTempView('TestTable')"
      ],
      "metadata": {
        "id": "EKjGC3AjbYt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_result = spark.sql(\"Select * from TestTable\")"
      ],
      "metadata": {
        "id": "uIrmD-Mfbo9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_result.show()"
      ],
      "metadata": {
        "id": "SGPInLUVb2bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_dataframe.select(spark_dataframe.Number).orderBy(spark_dataframe.Number.asc()).collect()"
      ],
      "metadata": {
        "id": "funvsBo-b4rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhbiZBoRdWWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}